{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ENmW1wp0h2ri"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets\n",
        "!pip install transformers[torch]\n",
        "!pip install accelerate -U\n",
        "!pip install transformers datasets evaluate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "salS3AvMisJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "xray=load_dataset(\"keremberke/chest-xray-classification\" ,\"full\")\n"
      ],
      "metadata": {
        "id": "9e7D3CuYisp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset Loading\n",
        "\n",
        "A dataset named xray is loaded, containing training, validation, and test sets.\n",
        "The dataset seems to include image file paths, actual images, and corresponding labels (0 for 'NORMAL' and 1 for 'PNEUMONIA')."
      ],
      "metadata": {
        "id": "df3vm_VB-Czb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xray"
      ],
      "metadata": {
        "id": "b00-d_F1jI-d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xray = xray.remove_columns(\"image_file_path\")"
      ],
      "metadata": {
        "id": "t1HZcszYjMyq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xray[\"train\"][10]"
      ],
      "metadata": {
        "id": "MjisJqVhjSv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preprocessing\n",
        "\n",
        "Image file paths are removed from the dataset.\n",
        "Labels and their corresponding IDs are extracted and stored in dictionaries (label2id and id2label)."
      ],
      "metadata": {
        "id": "QKNaewLk-Yw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#xray\n",
        "labels = xray[\"train\"].features[\"labels\"].names\n",
        "label2id, id2label = dict(), dict()\n",
        "for i, label in enumerate(labels):\n",
        "    label2id[label] = str(i)\n",
        "    id2label[str(i)] = label"
      ],
      "metadata": {
        "id": "N3xS45fRjStE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id2label"
      ],
      "metadata": {
        "id": "ywXjSVIIjSrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Preprocessing\n",
        "\n",
        "An image processor is loaded using the Hugging Face Transformers library (AutoImageProcessor).\n",
        "Preprocessing transformations (e.g., resizing, normalization) are defined using the torchvision.transforms module."
      ],
      "metadata": {
        "id": "z1gke7Z1-_x8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoImageProcessor\n",
        "\n",
        "checkpoint = \"microsoft/resnet-50\"\n",
        "image_processor = AutoImageProcessor.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "3bZedtTyjSn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.transforms import RandomResizedCrop, Compose, Normalize, ToTensor\n",
        "\n",
        "normalize = Normalize(mean=image_processor.image_mean, std=image_processor.image_std)\n",
        "size = (\n",
        "    image_processor.size[\"shortest_edge\"]\n",
        "    if \"shortest_edge\" in image_processor.size\n",
        "    else (image_processor.size[\"height\"], image_processor.size[\"width\"])\n",
        ")\n",
        "_transforms = Compose([RandomResizedCrop(size), ToTensor(), normalize])"
      ],
      "metadata": {
        "id": "HkjzuKjUjuGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transforms(examples):\n",
        "    examples[\"pixel_values\"] = [_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]]\n",
        "    del examples[\"image\"]\n",
        "    return examples"
      ],
      "metadata": {
        "id": "3Q7-fwz2jxPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xray = xray.with_transform(transforms)"
      ],
      "metadata": {
        "id": "u0OKUeW9kM7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DefaultDataCollator\n",
        "\n",
        "data_collator = DefaultDataCollator()"
      ],
      "metadata": {
        "id": "U0vVI2bkjxKg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "\n",
        "accuracy = evaluate.load(\"accuracy\")"
      ],
      "metadata": {
        "id": "lPjMKDTZjxHq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    predictions = np.argmax(predictions, axis=1)\n",
        "    return accuracy.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "SxLRG9oHkXbb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training Configuration:\n",
        "\n",
        "The training configuration is set using the TrainingArguments class, specifying parameters like output directory, learning rate, batch size, etc.\n",
        "An image classification model is loaded using the Hugging Face Transformers library (AutoModelForImageClassification)."
      ],
      "metadata": {
        "id": "mPP-sk8Q_hml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification, TrainingArguments, Trainer\n",
        "\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    checkpoint,\n",
        "    num_labels=len(labels),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    ignore_mismatched_sizes=True,\n",
        ")"
      ],
      "metadata": {
        "id": "TgTb5qw1kXZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"Cheese_xray\",\n",
        "    remove_unused_columns=False,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    gradient_accumulation_steps=4,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=1,\n",
        "    warmup_ratio=0.1,\n",
        "    logging_steps=10,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"accuracy\",\n",
        "    push_to_hub=True,\n",
        ")"
      ],
      "metadata": {
        "id": "MDWF3DpckXWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=data_collator,\n",
        "    train_dataset=xray[\"train\"],\n",
        "    eval_dataset=xray[\"test\"],\n",
        "    tokenizer=image_processor,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "6urCaoZukXTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the validation set\n",
        "results = trainer.evaluate()\n",
        "\n",
        "# Print the evaluation results\n",
        "print(results)\n"
      ],
      "metadata": {
        "id": "nJULXrPCU7xQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xray"
      ],
      "metadata": {
        "id": "JxRnFGDfV5az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(xray[\"validation\"].features)\n"
      ],
      "metadata": {
        "id": "8x5knOZ2WU7-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming your model is a ResNet model\n",
        "# You may need to adjust this based on your actual model architecture\n",
        "last_conv_layer = None\n",
        "\n",
        "for name, module in model.named_modules():\n",
        "    if isinstance(module, torch.nn.modules.conv.Conv2d):\n",
        "        last_conv_layer = module\n",
        "\n",
        "# Check if a valid last convolutional layer was found\n",
        "if last_conv_layer is not None:\n",
        "    print(\"Found last convolutional layer:\", last_conv_layer)\n",
        "else:\n",
        "    print(\"No valid last convolutional layer found in the model.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ORB-xl4qYUTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load model from the last checkpoint\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    \"barghavani/Cheese_xray\",\n",
        "    num_labels=len(labels),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id,\n",
        "    ignore_mismatched_sizes=True,\n",
        ")\n"
      ],
      "metadata": {
        "id": "upQm1Kc_6zag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub()"
      ],
      "metadata": {
        "id": "0MB-8UW-muuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download unseen data to check the accuracyy of model\n",
        "ds = load_dataset(\"keremberke/chest-xray-classification\", \"full\", split=\"validation\")\n",
        "\n",
        "image = ds[\"image\"][0]\n",
        "image"
      ],
      "metadata": {
        "id": "kRxkIZyAmyNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "classifier = pipeline(\"image-classification\", model=\"barghavani/Cheese_xray\")\n",
        "classifier(image)\n"
      ],
      "metadata": {
        "id": "7ZfeB7oH0FBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "by 66% it predict to be normal and by 34% it is PNEUMONIA"
      ],
      "metadata": {
        "id": "R2bKauJXAFCw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoImageProcessor\n",
        "import torch\n",
        "\n",
        "image_processor = AutoImageProcessor.from_pretrained(\"barghavani/Cheese_xray\")\n",
        "inputs = image_processor(image, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "ZXMvEJAL0Htl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification\n",
        "\n",
        "model = AutoModelForImageClassification.from_pretrained(\"barghavani/Cheese_xray\")\n",
        "with torch.no_grad():\n",
        "    logits = model(**inputs).logits"
      ],
      "metadata": {
        "id": "fsq2tiB20Ksd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_label = logits.argmax(-1).item()\n",
        "model.config.id2label[predicted_label]"
      ],
      "metadata": {
        "id": "e8WgmC__0NPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Demo\n",
        "\n",
        "https://huggingface.co/spaces/barghavani/barghavani-Cheese_xray"
      ],
      "metadata": {
        "id": "V6k4tl2AaxmN"
      }
    }
  ]
}